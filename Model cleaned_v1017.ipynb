{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('twitter').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+-------+--------+--------+---------+\n",
      "|               tweet|Compound|Negative|Neutral|Positive|original|sentiment|\n",
      "+--------------------+--------+--------+-------+--------+--------+---------+\n",
      "|Happy Monday twit...|   0.778|   0.564|   0.09|   0.346|positive|        4|\n",
      "|C'MON STEWARDESS!...|     0.0|     1.0|    0.0|     0.0|negative|        0|\n",
      "|@saraeden That so...|   0.806|   0.452|    0.0|   0.548|positive|        4|\n",
      "|@mitchelmusso I R...|   0.684|   0.771|    0.0|   0.229|negative|        0|\n",
      "|I don't know what...|     0.0|     1.0|    0.0|     0.0|negative|        0|\n",
      "|Changeling. So fa...|    0.03|   0.369|   0.31|   0.321|negative|        0|\n",
      "|@kateadams will t...|     0.0|     1.0|    0.0|     0.0|positive|        4|\n",
      "|cuddling with mys...|     0.0|     1.0|    0.0|     0.0|negative|        0|\n",
      "|@mcttron Rip it u...|     0.0|     1.0|    0.0|     0.0|positive|        4|\n",
      "|@eatsomemore hell...|     0.0|     1.0|    0.0|     0.0|positive|        4|\n",
      "| I cant tomorrow ...|     0.0|     1.0|    0.0|     0.0|negative|        0|\n",
      "|@jesscorrie aww  ...|   0.836|    0.44|    0.0|    0.56|positive|        4|\n",
      "|@Daddys_pet yes i...|   0.796|   0.426|    0.0|   0.574|positive|        4|\n",
      "|@ClarenceHill You...|     0.0|     1.0|    0.0|     0.0|negative|        0|\n",
      "|Opps what i meant...|   0.667|   0.817|    0.0|   0.183|positive|        4|\n",
      "|@JoannaHang I was...|  -0.585|   0.678|  0.322|     0.0|negative|        0|\n",
      "|gonna get some Be...|    0.66|   0.649|    0.0|   0.351|positive|        4|\n",
      "|@theskorpion why ...|     0.0|     1.0|    0.0|     0.0|negative|        0|\n",
      "|@l3xi3sunshine ar...|  -0.494|    0.61|   0.39|     0.0|negative|        0|\n",
      "|eyes are so sore ...|  -0.775|   0.632|  0.317|   0.051|negative|        0|\n",
      "+--------------------+--------+--------+-------+--------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url =\"CSV_cleaned/tweets_sample2.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "df = spark.read.csv(SparkFiles.get(\"tweets_sample2.csv\"), sep=\",\", header=True)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+-------+--------+--------+---------+------+\n",
      "|               tweet|Compound|Negative|Neutral|Positive|original|sentiment|length|\n",
      "+--------------------+--------+--------+-------+--------+--------+---------+------+\n",
      "|Happy Monday twit...|   0.778|   0.564|   0.09|   0.346|positive|        4|   116|\n",
      "|C'MON STEWARDESS!...|     0.0|     1.0|    0.0|     0.0|negative|        0|   136|\n",
      "|@saraeden That so...|   0.806|   0.452|    0.0|   0.548|positive|        4|    54|\n",
      "|@mitchelmusso I R...|   0.684|   0.771|    0.0|   0.229|negative|        0|   132|\n",
      "|I don't know what...|     0.0|     1.0|    0.0|     0.0|negative|        0|    27|\n",
      "|Changeling. So fa...|    0.03|   0.369|   0.31|   0.321|negative|        0|    38|\n",
      "|@kateadams will t...|     0.0|     1.0|    0.0|     0.0|positive|        4|    35|\n",
      "|cuddling with mys...|     0.0|     1.0|    0.0|     0.0|negative|        0|    21|\n",
      "|@mcttron Rip it u...|     0.0|     1.0|    0.0|     0.0|positive|        4|    67|\n",
      "|@eatsomemore hell...|     0.0|     1.0|    0.0|     0.0|positive|        4|    43|\n",
      "| I cant tomorrow ...|     0.0|     1.0|    0.0|     0.0|negative|        0|    32|\n",
      "|@jesscorrie aww  ...|   0.836|    0.44|    0.0|    0.56|positive|        4|    67|\n",
      "|@Daddys_pet yes i...|   0.796|   0.426|    0.0|   0.574|positive|        4|    52|\n",
      "|@ClarenceHill You...|     0.0|     1.0|    0.0|     0.0|negative|        0|    41|\n",
      "|Opps what i meant...|   0.667|   0.817|    0.0|   0.183|positive|        4|   119|\n",
      "|@JoannaHang I was...|  -0.585|   0.678|  0.322|     0.0|negative|        0|    58|\n",
      "|gonna get some Be...|    0.66|   0.649|    0.0|   0.351|positive|        4|    58|\n",
      "|@theskorpion why ...|     0.0|     1.0|    0.0|     0.0|negative|        0|    51|\n",
      "|@l3xi3sunshine ar...|  -0.494|    0.61|   0.39|     0.0|negative|        0|    33|\n",
      "|eyes are so sore ...|  -0.775|   0.632|  0.317|   0.051|negative|        0|   119|\n",
      "+--------------------+--------+--------+-------+--------+--------+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a length column to be used as a future feature\n",
    "data = df.withColumn('length', length(df['tweet']))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the features to the data set\n",
    "\n",
    "pos_neg_to_num = StringIndexer(inputCol='original',outputCol='label')\n",
    "pos_neg_to_num2 = StringIndexer(inputCol='Compound',outputCol='compound2')\n",
    "pos_neg_to_num3 = StringIndexer(inputCol='Positive',outputCol='positive2')\n",
    "pos_neg_to_num4 = StringIndexer(inputCol='Negative',outputCol='negative2')\n",
    "pos_neg_to_num5 = StringIndexer(inputCol='Neutral',outputCol='neutral2')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n",
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'compound2'], outputCol='features')\n",
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'compound2','negative2','positive2','neutral2'], outputCol='features')\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'length','compound2','negative2','positive2','neutral2'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num,pos_neg_to_num2,pos_neg_to_num3,pos_neg_to_num4,pos_neg_to_num5,tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(data)\n",
    "cleaned = cleaner.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|         stop_tokens|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|  1.0|[happy, monday, t...|(262149,[21872,37...|\n",
      "|  0.0|[c'mon, stewardes...|(262149,[304,3091...|\n",
      "|  1.0|[@saraeden, sound...|(262149,[113432,1...|\n",
      "|  0.0|[@mitchelmusso, r...|(262149,[14,33053...|\n",
      "|  0.0|       [know, watch]|(262149,[140931,2...|\n",
      "|  0.0|[changeling., far...|(262149,[155321,1...|\n",
      "|  1.0|[@kateadams, frui...|(262149,[88244,15...|\n",
      "|  0.0|          [cuddling]|(262149,[38629,26...|\n",
      "|  1.0|[@mcttron, rip, u...|(262149,[5381,266...|\n",
      "|  1.0|[@eatsomemore, he...|(262149,[19140,28...|\n",
      "|  0.0|[, cant, tomorrow...|(262149,[29129,12...|\n",
      "|  1.0|[@jesscorrie, aww...|(262149,[55724,82...|\n",
      "|  1.0|[@daddys_pet, yes...|(262149,[39276,54...|\n",
      "|  0.0|[@clarencehill, r...|(262149,[87348,15...|\n",
      "|  1.0|[opps, meant, was...|(262149,[2054,844...|\n",
      "|  0.0|[@joannahang, bad...|(262149,[16143,57...|\n",
      "|  1.0|[gonna, get, bett...|(262149,[99895,12...|\n",
      "|  0.0|[@theskorpion, u,...|(262149,[24150,11...|\n",
      "|  0.0|[@l3xi3sunshine, ...|(262149,[113318,1...|\n",
      "|  0.0|[eyes, sore, , wa...|(262149,[8449,219...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleaned.show()\n",
    "\n",
    "cleaned.select(['label','stop_tokens', 'features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# Break data down into a training set and a testing set\n",
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+-------+--------+--------+---------+------+-----+---------+---------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               tweet|Compound|Negative|Neutral|Positive|original|sentiment|length|label|compound2|positive2|negative2|neutral2|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------+-------+--------+--------+---------+------+-----+---------+---------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| OMG! i hear ever...|     0.0|     1.0|    0.0|     0.0|negative|        0|    47|  0.0|      0.0|      0.0|      0.0|     0.0|[, omg!, i, hear,...|[, omg!, hear, ev...|(262144,[37101,10...|(262144,[37101,10...|(262149,[37101,10...|[-534.49270119952...|[2.79311344013064...|       1.0|\n",
      "| Wheres my mommmy...|   0.447|   0.506|    0.0|   0.494|negative|        0|    21|  0.0|    668.0|    501.0|    565.0|     0.0|[, wheres, my, mo...|[, wheres, mommmy...|(262144,[21058,17...|(262144,[21058,17...|(262149,[21058,17...|[-3624.9502250705...|[4.79556855376075...|       1.0|\n",
      "| back to no inter...|  -0.296|   0.577|  0.423|     0.0|negative|        0|    21|  0.0|      2.0|      0.0|     40.0|    33.0|[, back, to, no, ...|  [, back, internet]|(262144,[132270,1...|(262144,[132270,1...|(262149,[132270,1...|[-296.93108519453...|[1.0,1.1835276884...|       0.0|\n",
      "| going home. Miss...|  -0.153|   0.714|  0.286|     0.0|negative|        0|    29|  0.0|     10.0|      0.0|     11.0|    50.0|[, going, home., ...|[, going, home., ...|(262144,[62713,13...|(262144,[62713,13...|(262149,[62713,13...|[-365.90317034660...|[1.0,3.9543267218...|       0.0|\n",
      "| im in the mood f...|     0.0|     1.0|    0.0|     0.0|negative|        0|    53|  0.0|      0.0|      0.0|      0.0|     0.0|[, im, in, the, m...|[, im, mood, choc...|(262144,[58547,89...|(262144,[58547,89...|(262149,[58547,89...|[-504.56963651735...|[0.99999999999998...|       0.0|\n",
      "+--------------------+--------+--------+-------+--------+--------+---------+------+-----+---------+---------+---------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.671703374583188\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(f\"Accuracy of model at predicting reviews was: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'length','compound2'], outputCol='features') 0.5919176454727069\n",
    " \n",
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'compound2'], outputCol='features') 0.5707940034594462\n",
    "\n",
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features') 0.6008312043512044\n",
    "\n",
    "# clean_up = VectorAssembler(inputCols=['idf_token', 'length','compound2','negative2','positive2','neutral2'], outputCol='features') 0.6785473212243401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "predictor.save(\"sentiment_model.h5\")\n",
    "\n",
    "# write.overwrite().save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
